services:
  # PO Token Provider for YouTube (bypasses bot detection)
  # This is the "set and forget" solution for YouTube downloads
  bgutil-provider:
    image: brainicism/bgutil-ytdlp-pot-provider:latest
    container_name: instrumental-bgutil
    restart: unless-stopped
    mem_limit: 256m
    networks:
      - internal
    # No port exposed - only accessible within the docker network

  webui:
    build: .
    container_name: instrumental-webui
    hostname: instrumental-webui
    command: ["python", "-u", "-m", "flask", "--app", "app.webui.app:create_app()", "run", "--host", "0.0.0.0", "--port", "5000"]
    ports:
      - "5000:5000"
    mem_limit: 256m
    env_file: .env
    environment:
      - FLASK_ENV=production
      - FLASK_SECRET_KEY=${FLASK_SECRET_KEY:-change-me-in-production}
      - INCOMING_DIR=/data/incoming
      - MUSIC_LIBRARY=/data/output
      - WORKING_DIR=/data/working
      - LOG_DIR=/data/logs
      - ARCHIVE_DIR=/data/archive
      - QUARANTINE_DIR=/data/quarantine
      - DB_PATH=/data/db
      # PO Token Provider URL for yt-dlp (for YouTube bot detection bypass)
      - YTDLP_POT_PROVIDER_URL=http://instrumental-bgutil:4416
      # NAS sync trigger file (shared with nas-sync container via output volume)
      - SYNC_TRIGGER_FILE=/data/output/.sync_trigger
    volumes:
      - ./pipeline-data/incoming:/data/incoming
      - ./pipeline-data/working:/data/working
      - ./pipeline-data/output:/data/output
      - ./pipeline-data/db:/data/db
      - ./pipeline-data/logs:/data/logs
      - ./pipeline-data/archive:/data/archive
      - ./pipeline-data/quarantine:/data/quarantine
      - ./pipeline-data/config:/data/config
    networks:
      - internal
      - proxy
    depends_on:
      - bgutil-provider
    # Traefik labels commented out - using Cloudflare Tunnel instead
    # labels:
    #   - traefik.enable=true
    #   - traefik.docker.network=proxy
    #   - traefik.http.routers.instrumental-webui-nsystems.rule=Host(`instrumental.nsystems.live`)
    #   - traefik.http.routers.instrumental-webui-nsystems.entrypoints=websecure
    #   - traefik.http.routers.instrumental-webui-nsystems.tls=true
    #   - traefik.http.routers.instrumental-webui-nsystems.priority=120
    #   - traefik.http.routers.instrumental-webui-nsystems.middlewares=secure-headers@docker
    #   - traefik.http.services.instrumental-webui.loadbalancer.server.port=5000
    restart: unless-stopped

  instrumental-simple:
    build:
      context: .
      args:
        TARGET_DEVICE: gpu
    container_name: instrumental-simple
    hostname: instrumental-simple
    # Use -m so that relative imports inside app package work
    command: ["python", "-u", "-m", "app.main", "simple", "--daemon"]
    env_file: .env
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - TORCH_HOME=/models/torch
      - XDG_CACHE_HOME=/models/xdg
      - DEMUCS_CACHE=/models/demucs
      - DEMUCS_DEVICE=cuda
      - DEMUCS_JOBS=1
      - MUSIC_LIBRARY=/data/output
      # Encoding mode: v0 (default) or cbr320
      - MP3_ENCODING=cbr320
      # Where to send corrupt inputs: archive (default) or quarantine
      - CORRUPT_DEST=archive
      # Queue-based pipeline (Phase 2/3)
      - QUEUE_ENABLED=true
      - QUEUE_YOUTUBE_AUDIO=/queues/youtube_audio
      - QUEUE_YOUTUBE_VIDEO=/queues/youtube_video
      - QUEUE_OTHER=/queues/other
      - OUTPUTS_DIR=/data/outputs
    volumes:
      - ./pipeline-data/incoming:/data/incoming
      - ./pipeline-data/working:/data/working
      - ./pipeline-data/output:/data/output
      - ./pipeline-data/outputs:/data/outputs
      - ./pipeline-data/db:/data/db
      - ./pipeline-data/logs:/data/logs
      - ./pipeline-data/models:/models
      - ./pipeline-data/archive:/data/archive
      - ./pipeline-data/quarantine:/data/quarantine
      - ./queues/youtube_audio:/queues/youtube_audio
      - ./queues/youtube_video:/queues/youtube_video
      - ./queues/other:/queues/other
    networks:
      - internal
    restart: unless-stopped

  minio:
    image: quay.io/minio/minio:latest
    container_name: instrumental-minio
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    mem_limit: 256m
    environment:
      MINIO_ROOT_USER: ${MINIO_ACCESS_KEY}
      MINIO_ROOT_PASSWORD: ${MINIO_SECRET_KEY}
    volumes:
      - ./pipeline-data/minio-data:/data
    networks:
      - internal
      - proxy
    # Traefik labels commented out - using Cloudflare Tunnel instead
    # labels:
    #   - traefik.enable=true
    #   - traefik.docker.network=proxy
    #   # MinIO S3 API
    #   - traefik.http.routers.instrumental-minio-api-nsystems.rule=Host(`instrumental-s3.nsystems.live`)
    #   - traefik.http.routers.instrumental-minio-api-nsystems.entrypoints=websecure
    #   - traefik.http.routers.instrumental-minio-api-nsystems.tls=true
    #   - traefik.http.routers.instrumental-minio-api-nsystems.priority=120
    #   - traefik.http.routers.instrumental-minio-api-nsystems.middlewares=secure-headers@docker
    #   - traefik.http.routers.instrumental-minio-api-nsystems.service=instrumental-minio-api
    #   - traefik.http.services.instrumental-minio-api.loadbalancer.server.port=9000
    #   # MinIO Console
    #   - traefik.http.routers.instrumental-minio-console-nsystems.rule=Host(`instrumental-minio.nsystems.live`)
    #   - traefik.http.routers.instrumental-minio-console-nsystems.entrypoints=websecure
    #   - traefik.http.routers.instrumental-minio-console-nsystems.tls=true
    #   - traefik.http.routers.instrumental-minio-console-nsystems.priority=120
    #   - traefik.http.routers.instrumental-minio-console-nsystems.middlewares=secure-headers@docker
    #   - traefik.http.routers.instrumental-minio-console-nsystems.service=instrumental-minio-console
    #   - traefik.http.services.instrumental-minio-console.loadbalancer.server.port=9001
    restart: unless-stopped

  minio-mirror:
    build: .
    container_name: instrumental-minio-mirror
    command: ["python", "-u", "-m", "app.main", "minio-mirror"]
    mem_limit: 128m
    env_file: .env
    depends_on:
      - instrumental-simple
      - minio
    volumes:
      - ./pipeline-data/output:/data/output
      - ./pipeline-data/db:/data/db
      - ./pipeline-data/logs:/data/logs
    networks:
      - internal
    restart: unless-stopped

  filebrowser:
    image: filebrowser/filebrowser:latest
    container_name: instrumental-filebrowser
    # Run as root so it can manage root-owned files created by other containers
    user: "0:0"
    ports:
      - "8080:80"
    mem_limit: 64m
    volumes:
      - ./pipeline-data:/srv
      - ./test-data:/srv/test-data
      - ./pipeline-data/filebrowser/database:/database
      - ./pipeline-data/filebrowser/config:/config
    networks:
      - proxy
    # Traefik labels commented out - using Cloudflare Tunnel instead
    # labels:
    #   - traefik.enable=true
    #   - traefik.docker.network=proxy
    #   - traefik.http.routers.instrumental-files-nsystems.rule=Host(`instrumental-files.nsystems.live`)
    #   - traefik.http.routers.instrumental-files-nsystems.entrypoints=websecure
    #   - traefik.http.routers.instrumental-files-nsystems.tls=true
    #   - traefik.http.routers.instrumental-files-nsystems.priority=120
    #   - traefik.http.routers.instrumental-files-nsystems.middlewares=secure-headers@docker
    #   - traefik.http.services.instrumental-files.loadbalancer.server.port=80
    restart: unless-stopped

  deemix:
    image: registry.gitlab.com/bockiii/deemix-docker:latest
    container_name: instrumental-deemix
    restart: unless-stopped
    mem_limit: 256m
    ports:
      - "6595:6595"
    environment:
      - PUID=0
      - PGID=0
      - UMASK_SET=022
      - DEEMIX_SINGLE_USER=true
    volumes:
      # Persist Deemix config (cookies, logged-in session)
      - ./pipeline-data/deemix/config:/config
      # Write downloads directly into the instrumental-maker pipeline incoming directory
      - ./pipeline-data/incoming:/downloads
    networks:
      - proxy
    # Traefik labels commented out - using Cloudflare Tunnel instead
    # labels:
    #   - traefik.enable=true
    #   - traefik.docker.network=proxy
    #   - traefik.http.routers.instrumental-deemix-nsystems.rule=Host(`instrumental-deemix.nsystems.live`)
    #   - traefik.http.routers.instrumental-deemix-nsystems.entrypoints=websecure
    #   - traefik.http.routers.instrumental-deemix-nsystems.tls=true
    #   - traefik.http.routers.instrumental-deemix-nsystems.priority=120
    #   - traefik.http.routers.instrumental-deemix-nsystems.middlewares=secure-headers@docker
    #   - traefik.http.services.instrumental-deemix.loadbalancer.server.port=6595

  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: instrumental-cloudflared
    restart: unless-stopped
    command: tunnel --no-autoupdate run --token eyJhIjoiMmZhODcwNWRiOWFhYzU5ZmJhMmIyYmQyNTg1Y2UyNDkiLCJ0IjoiMDQ3NGFiNzItY2FkYS00MmZkLTk0YTctMThkZjUxNDc2MzVmIiwicyI6IlpqWmpOemd3WkRFdFpXVXlaQzAwTWpZMkxUZ3hZVEl0TUdReU5tSm1OR0kwWVdZMCJ9
    networks:
      - proxy
      - internal
    depends_on:
      - webui
      - minio
      - filebrowser
      - deemix

  youtube-retriever:
    build:
      context: ./services/youtube_retriever
    container_name: instrumental-youtube-retriever
    restart: unless-stopped
    env_file: .env
    environment:
      # Operating mode: audio | video | both
      - YTDL_MODE=audio
      # Audio format for extraction: m4a | flac | mp3 | wav
      - YTDL_AUDIO_FORMAT=m4a
      # Duration validation tolerances
      - YTDL_DURATION_TOL_SEC=2.0
      - YTDL_DURATION_TOL_PCT=0.01
      - YTDL_FAIL_ON_DURATION_MISMATCH=true
      # yt-dlp options
      - YTDL_QUIET=false
      - YTDL_NO_WARNINGS=true
      - YTDL_SOCKET_TIMEOUT=30
      # Logging
      - LOG_DIR=/data/logs
      - LOG_LEVEL=info
      # Work directory
      - WORKING_DIR=/tmp/ytdl_work
      # Request handling (watch for .txt files with URLs)
      - REQUESTS_DIR=/data/requests
    volumes:
      - ./pipeline-data/logs:/data/logs
      - ./pipeline-data/requests:/data/requests
      - ./queues/youtube_audio:/queues/youtube_audio
      - ./queues/youtube_video:/queues/youtube_video
      - /tmp/ytdl_work:/tmp/ytdl_work
    networks:
      - internal
    depends_on:
      - instrumental-simple

  deemix-retriever:
    build:
      context: ./services/deemix_retriever
    container_name: instrumental-deemix-retriever
    restart: unless-stopped
    env_file: .env
    environment:
      # Download quality (FLAC, MP3_320, MP3_128, AAC_256, etc.)
      - DEEMIX_QUALITY=${DEEMIX_QUALITY:-FLAC}
      # Number of parallel download workers
      - MAX_CONCURRENT_DEEMIX=${MAX_CONCURRENT_DEEMIX:-2}
      # Seconds between checking for new requests
      - WATCH_INTERVAL=10
      # Timeout per download (seconds, default 30 min)
      - DEEMIX_DOWNLOAD_TIMEOUT=1800
      # Log level
      - LOG_LEVEL=INFO
      # Skip non-critical errors and continue
      - SKIP_ON_ERROR=true
      # Queue paths
      - QUEUE_OTHER=/queues/other/
      - DEEMIX_WORKING_DIR=/tmp/deemix_retriever
      - DEEMIX_CACHE_DIR=/home/deemix/.cache/deemix
      - DEEMIX_CONFIG_DIR=/home/deemix/.config/deemix
    volumes:
      - ./pipeline-data/logs:/data/logs
      - ./queues/other:/queues/other
      - deemix_retriever_cache:/home/deemix/.cache/deemix
      - deemix_retriever_config:/home/deemix/.config/deemix
      - /tmp/deemix_retriever:/tmp/deemix_retriever
    networks:
      - internal
    depends_on:
      - instrumental-simple
    healthcheck:
      test: ["CMD", "test", "-d", "/queues/other"]
      interval: 30s
      timeout: 10s
      retries: 3

  nas-sync:
    build:
      context: ./services/nas_sync_service
    container_name: instrumental-nas-sync
    restart: unless-stopped
    environment:
      # Core paths
      - OUTPUTS_DIR=/data/outputs
      - NAS_SYNC_WORK_DIR=/data/nas-sync-work
      - NAS_SYNC_LOG_FILE=/data/logs/nas-sync.jsonl
      
      # Sync backend: rsync | s3 | scp | local
      - NAS_SYNC_METHOD=${NAS_SYNC_METHOD:-rsync}
      
      # Remote root paths (backend-specific)
      - NAS_REMOTE_ROOT_AUDIO=${NAS_REMOTE_ROOT_AUDIO:-}
      - NAS_REMOTE_ROOT_VIDEO=${NAS_REMOTE_ROOT_VIDEO:-}
      - NAS_REMOTE_ROOT_STEMS=${NAS_REMOTE_ROOT_STEMS:-}
      
      # Route definitions (JSON string)
      - NAS_SYNC_ROUTES=${NAS_SYNC_ROUTES:-}
      
      # Rsync options
      - NAS_RSYNC_BW_LIMIT=${NAS_RSYNC_BW_LIMIT:-0}
      - NAS_RSYNC_COMPRESS=${NAS_RSYNC_COMPRESS:-true}
      
      # S3 options (if using S3 backend)
      - NAS_S3_BUCKET=${NAS_S3_BUCKET:-}
      - NAS_S3_PREFIX=${NAS_S3_PREFIX:-instrumental-maker}
      - NAS_S3_REGION=${NAS_S3_REGION:-us-east-1}
      - NAS_S3_ENDPOINT=${NAS_S3_ENDPOINT:-}
      
      # SCP options (if using SCP backend)
      - NAS_SCP_HOST=${NAS_SCP_HOST:-}
      - NAS_SCP_USER=${NAS_SCP_USER:-}
      - NAS_SCP_KEY=${NAS_SCP_KEY:-/home/user/.ssh/id_rsa}
      
      # Behavior
      - NAS_SKIP_ON_MISSING_REMOTE=${NAS_SKIP_ON_MISSING_REMOTE:-true}
      - NAS_DRY_RUN=${NAS_DRY_RUN:-false}
      - NAS_DAEMON_MODE=${NAS_DAEMON_MODE:-true}
      - NAS_POLL_INTERVAL_SEC=${NAS_POLL_INTERVAL_SEC:-5}
      
      # Logging
      - NAS_LOG_LEVEL=${NAS_LOG_LEVEL:-INFO}
    
    volumes:
      - ./pipeline-data/outputs:/data/outputs
      - ./pipeline-data/logs:/data/logs
      - ./pipeline-data/nas-sync-work:/data/nas-sync-work
      # Mount NAS/storage as needed (customize for your setup)
      # - /mnt/nas:/mnt/nas
      # - ~/.ssh:/root/.ssh:ro  # For SCP backend
    
    networks:
      - internal
    
    depends_on:
      - instrumental-simple

networks:
  internal:
  proxy:
    external: false

volumes:
  deemix_retriever_cache:
  deemix_retriever_config: